---
title: "Homework 3"
author: "Langdon Holmes"
date-modified: "today"
subtitle: "Multilevel Modeling"
format: pdf
code-fold: false
code-overflow: wrap
editor: 
  markdown: 
    wrap: 80
---

```{r, echo=FALSE, message = FALSE, warning = FALSE}
library(haven) # read .sav file
library(nlme) # allows constraints on residual correlation matrix
library(stargazer) # LaTeX tables
library(performance) # ICC
popular <- read_sav("../data/popular.sav")
popularmv <- read_sav("../data/popularmv.sav")
```

# 1
In a univariate random intercept, random slope model, test the effect of SEX on student-rated
popularity (POPULAR). Now test the effect of SEX on teacher-rated popularity (TEACHPOP).
Interpret each set of results in isolation. [12]

```{r, warning = FALSE, output = "asis"}
studentpopularity <- lme(POPULAR~SEX,
                    random=~SEX|SCHOOL,
                    data=popular,
                    method='ML')

teacherpopularity <- lme(TEACHPOP~SEX,
                    random=~SEX|SCHOOL,
                    data=popular,
                    method='ML')

stargazer(studentpopularity, teacherpopularity, header=FALSE, 
          column.labels = c("Student Popularity", "Teacher Popularity")
          )

getVarCov(studentpopularity)
```

```{r}
getVarCov(teacherpopularity)
```

I fit a model with a random intercept and random slope to test whether the student's sex predicts their popularity. There is a positive, significant slope, which means that women (coded as 1) are more popular than men (coded as 0) in this dataset.

I fit a model with a random intercept and a random slope to test whether the student's sex predicts their teacher's popularity. There is a positive, significant slope, which means that female students (coded as 1) are more likely to view their teachers as popular.

# 2
In a joint multivariate model that allows all intercepts and slopes to covary, but does not allow
the level-1 residuals to covary across variables, assess the same effects you did in (1). Report and
interpret the results. What is better about the analysis in (2) vs. (1)? [12]

```{r}
allpopularity <- lme(popst~0+conss+sexs+const+sext,
                    random=list(school=~0+conss+sexs+const+sext),
                    weights=varIdent(form=~1|dv),
                    data=popularmv,
                    method='ML',
                    control=lmeControl(maxIter=300,msMaxIter=300,niterEM=100,msMaxEval=500))
summary(allpopularity)
getVarCov(allpopularity)
```

To test whether sex predicts student popularity and teacher popularity, I developed a multivariate, multilevel model with school as a clustering variable. Sex is a significant predictor of both student ($T=14.25, p<0.05$) and teacher popularity ($T=7.58, p<0.05$). The model indicates that student popularity is 0.08 higher for women, and teacher popularity is 0.23 higher for women. Both student and teacher popularity is higher for women.

While the results are effectively the same, this approach is better because we now have a single model, which is more parsimonious than fitting two separate models, and allows us to estimate the covariance between predictors for each response variable. The covariance matrix demonstrates that teacher and student popularity scores covary (0.79), but the slope estimates do not covary (0.08). This indicates that teacher and student popularity are likely strongly correlated, but the effect of sex on these two response variables is substantially different.

# 3
Now test the effect of the level-2 predictor teacher experience (TEXP) on both student-rated
and teacher-rated popularity (without SEX in the model). Report and interpret the results. [12]

```{r}
model.texp <- lme(popst~0+conss+texps+const+texpt,
                    random=list(school=~0+conss+const),
                    weights=varIdent(form=~1|dv),
                    data=popularmv,
                    method='ML',
                    control=lmeControl(maxIter=300,msMaxIter=300,niterEM=100,msMaxEval=500)) #increase iterations for convergence
summary(model.texp)
getVarCov(model.texp)
```

To test whether teacher experience predicts student popularity and teacher popularity, I developed a multivariate, multilevel model with school as a clustering variable. Teacher experience is a significant predictor of both student ($T=8.45, p<0.05$) and teacher popularity ($T=6.54, p<0.05$). The model indicates that student popularity increases by 0.09 for every unit of teacher experience, and teacher popularity increases by 0.07 for every unit of teacher experience. Both students and teachers are rated as more popular when the teacher has more experience.

# 4
You have now learned at least two ways to formally test the hypothesis that the effects in (3)
are equal (the deviance test and a multiparameter test). Use both of these methods to test the
hypothesis of equal slopes. Report and interpret the results. Are the p-values the same? Close?
Report them to as many decimal places as possible. [12]

```{r}
library(car)
linearHypothesis(model.texp,c('texps=texpt'),verbose=TRUE)
```

The $\chi^{2}$ test is reported above, which results in an extremely small p-value ($\chi^{2} = 25.626, p=0.0000004144$). I couldn't figure out how to run a multiparameter test on a multivariate model in R, so I performed the contrast in SPSS (sadly...) using the contrast matrix [0, 1, 0, -1]. Results are reported below:

| Contrast Estimates |          |            |         |            |       |      |           |           |
|--------------------|----------|------------|---------|------------|-------|------|-----------|-----------|
| Contrast           | Estimate | Std. Error | df      | Test Value | t     | Sig. | 95% Lower | 95% Upper |
| L1                 | .021042  | .004143    | 102.200 | 0          | 5.079 | .000 | .012824   | .029261   |

				
The multiparameter test was significant, $t = 5.079, p= 0.000002$.

Either test would provide sufficient evidence to reject the null hypothesis that the slopes are equal. Both p-values are extremely small, but the deviance test yields a smaller p-value.



# 5 Power Analysis
Using MLPowSim, conduct an a priori power analysis for the slope point estimates in the
following multilevel model, with conjectured parameter values as indicated:


Limit your attention to a potential data set with 40 clusters of size 10 each, and maximum
likelihood (ML) estimation. Assume the predictors are each standard normal both at level-1 and
level-2. What is the approximate power for detecting each slope at   .05 ? Speculate about
why these power estimates are so different even though both population values are .2. [12]

```{r, echo=FALSE, include=FALSE}
###     A programme to obtain the power of parameters in 2 level  
#       balanced model  with  Normal response				
#                    generated on 03/10/21
###~~~~~~~~~~~~~~~~~    Required packages  ~~~~~~~~~~~~~~~~~~~~~###
    library(MASS)
    library(lme4)
###~~~~~~~~~~~~~~~~~~~     Initial inputs    ~~~~~~~~~~~~~~~~~~~~###

set.seed(2374)
siglevel<-0.050
z1score<-abs(qnorm(siglevel))
simus<-500
n1low<-10
n1high<-10
n1step<-0
n2low<-40
n2high<-40
n2step<-0
npred<-2
randsize<-2
beta<-c(0.000000,0.200000,0.200000)
betasize<-length(beta)
effectbeta<-abs(beta)
sgnbeta<-sign(beta)
randcolumn<-c(2.000000)
meanpred<-c(0,0.000000,0.000000)
varpred<-c(0,1.000000,1.000000)
varpred2<-c(0,1.000000,1.000000)
sigma2u<-matrix(c(1.000000,0.500000,0.500000,1.000000),randsize,randsize)
sigmae<-sqrt(0.900000)
n1range<-seq(n1low,n1high,n1step)
n2range<-seq(n2low,n2high,n2step)
n1size<-length(n1range)
n2size<-length(n2range)
totalsize<-n1size*n2size
finaloutput<-matrix(0,totalsize,6*betasize)
rowcount<-1
##-----------------        Inputs for model fitting       -----------------##

fixname<-c("x0","x1","x2")
fixform<-"1+x1+x2"
randform<-"(x1|l2id)"
expression<-paste(c(fixform,randform),collapse="+")
modelformula<-formula(paste("y ~",expression))
data<-vector("list",2+length(fixname))
names(data)<-c("l2id","y",fixname)

#####--------- Initial input for power in two approaches ----------------#####

   powaprox<-vector("list",betasize)
    names(powaprox)<-c("b0","b1","b2")
     powsde<-powaprox

cat("               The programme was executed at", date(),"\n")
cat("   --------------------------------------------------------------------\n")

 for(n2 in seq(n2low,n2high,n2step)){
  for(n1 in seq(n1low,n1high,n1step)){

                                             length=n1*n2
                                            x<-matrix(1,length,betasize)
                                           z<-matrix(1,length,randsize)
                                          l2id<-rep(c(1:n2),each=n1)
                                         sdepower<-matrix(0,betasize,simus)
                                       powaprox[1:betasize]<-rep(0,betasize)
                                      powsde<-powaprox

cat(" Start of simulation for sample sizes of ",n1," micro and ",n2,"macro units\n")
  for(iter in 1:simus){

                       if(iter/10==floor(iter/10)){
                                                   cat(" Iteration remain=",simus-iter,"\n")
                                                  }
#######------------       To set up X matrix          --------------########

            micpred<-rnorm(length,meanpred[2],sqrt(varpred[2]))
             macpred<-rnorm(n2,0,sqrt(varpred2[2]))
              macpred<-rep(macpred,each=n1)
               x[,2]<-micpred+macpred
            micpred<-rnorm(length,meanpred[3],sqrt(varpred[3]))
             macpred<-rnorm(n2,0,sqrt(varpred2[3]))
              macpred<-rep(macpred,each=n1)
               x[,3]<-micpred+macpred

#######------------       To set up Z matrix          --------------########

                for(j in 2:dim(z)[2])
                 z[,j]<-x[,randcolumn[j-1]] 

#####-----------------------------------------------------------------------##### 
                  e<-rnorm(length,0,sigmae)
                   u<-mvrnorm(n2,rep(0,randsize),sigma2u)
                    fixpart<-x%*%beta
                     randpart<-rowSums(z*u[l2id,])
                      y<-fixpart+randpart+e
##-------------------        Inputs for model fitting       ---------------##

  data$l2id<-as.factor(l2id)
  data$y<-y
    data$x0<-x[,1]
    data$x1<-x[,2]
    data$x2<-x[,3]
###~~~~~~~~~~      Fitting the model using lmer funtion    ~~~~~~~~~~###

(fitmodel <- lmer(modelformula,data,REML="FALSE"))

######~~~~~~~~~~   To obtain the power of parameter(s) ~~~~~~~~~~######

estbeta<-fixef(fitmodel)
 sdebeta<-sqrt(diag(vcov(fitmodel)))
  for(l in 1:betasize)
  {  
   cibeta<-estbeta[l]-sgnbeta[l]*z1score*sdebeta[l]
    if(beta[l]*cibeta>0)              powaprox[[l]]<-powaprox[[l]]+1
      sdepower[l,iter]<-as.numeric(sdebeta[l])
  }  
##------------------------------------------------------------------------##
        } ##  iteration end here

 ###---------                  Powers and their CIs             ---------###

                        for(l in 1:betasize){

meanaprox<-powaprox[[l]]<-unlist(powaprox[[l]]/simus)
Laprox<-meanaprox-z1score*sqrt(meanaprox*(1-meanaprox)/simus)
Uaprox<-meanaprox+z1score*sqrt(meanaprox*(1-meanaprox)/simus)
meansde<-mean(sdepower[l,])
varsde<-var(sdepower[l,])
USDE<-meansde-z1score*sqrt(varsde/simus)
LSDE<-meansde+z1score*sqrt(varsde/simus)
powLSDE<- pnorm(effectbeta[l]/LSDE-z1score)
powUSDE<- pnorm(effectbeta[l]/USDE-z1score)
powsde[[l]]<-pnorm(effectbeta[l]/meansde-z1score)


		###---------   Restrict the CIs within 0 and 1	---------##
				if(Laprox<0) Laprox<-0
				if(Uaprox>1) Uaprox<-1
				if(powLSDE<0) powLSDE<-0
				if(powUSDE>1) powUSDE<-1

finaloutput[rowcount,(6*l-5):(6*l-3)]<-c(Laprox,meanaprox,Uaprox)
finaloutput[rowcount,(6*l-2):(6*l)]<-c(powLSDE,powsde[[l]],powUSDE)

                                           } 

###~~~~~~~~~~            Set out the results in a data frame    ~~~~~~~~~~###

rowcount<-rowcount+1
cat("--------------------------------------------------------------------\n")
                               } ## end of the loop  over the first level
                           } ## end of the loop  over the second level

 ###---------         Export output in a file                      ---------###

finaloutput<-as.data.frame(round(finaloutput,3))
 output<-data.frame(cbind(rep(n2range,each=n1size),rep(n1range,n2size),finaloutput))
  names(output)<-c("N","n","zLb0","zpb0","zUb0","sLb0","spb0","sUb0","zLb1","zpb1","zUb1","sLb1","spb1","sUb1","zLb2","zpb2","zUb2","sLb2","spb2","sUb2")
output
```

```{r}
output
```


In a dataset with 40 clusters of 10 observations, the power to detect the random slope $\beta_{1j}$ is 0.349, and the power to detect the fixed slope $\beta_{2j}$ is a comfortable 0.993. The statistical power of the two slopes is dramatically different because we need to estimate additional parameters to calculate a random effect. This is true even though the effect size is the same for the two variables. We should probably look to have more than 10 observations for each cluster in a mixed effects model.

# Extra Credit
Compose a poem (any type: haiku, limerick, sonnet, ballad, free verse... whatever
you like) describing how multilevel modeling makes you feel. [+3]

I wrote a haiku:  
A model's a thought  
Novelty unconsidered  
Layers provide nuance  

But I couldn't resist...  
![MLM Rap by ChatGPT](mlm-poem.png)
