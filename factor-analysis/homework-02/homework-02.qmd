---
title: "Homework 2"
author: "Langdon Holmes"
date-modified: "today"
subtitle: "Factor Analysis"
format: pdf
code-fold: false
code-overflow: wrap
editor: 
  markdown: 
    wrap: 80
---

# Data

```{r}
values <- c(
  1.00, .61, 1.00, .64, .50, 1.00, .07, .02, .02, 1.00, .14, .13,  .04,
  .51, 1.00, .07, .08, -.03, .46, .51, 1.00, .04, -.05, -.01,  .28, .29,
  .13, 1.00, .08, .02, .08, .29, .31, .19, .46, 1.00, .06,  -.02, .01,
  .47, .41, .31, .66, .55, 1.00, -.02, -.07, -.01, .10, .18,  .05, .16,
  .31, .20, 1.00, -.02, -.08, -.02, .14, .24, .18, .16, .39,  .28, .60,
  1.00, -.17, -.15, -.04, .05, .09, .05, .12, .26, .17, .46, .61, 1.00
  )

names <- c(
  "LE", "AC", "IN", "LI", "LD", "LA", "LR", "LS", "NL", "SY", "HE", "GE"
  )
```

## Wrangle

```{r}
x <- diag(12)
# Values are inserted column-wise, so we add to the upper tri
x[upper.tri(x, diag=TRUE)] <- values
# add the transpose to get the lower left
# but this results in 2.0 on the diagonal,
# so subtract diag(12) to get the full correlation matrix
x <- x + t(x) - diag(12)
rownames(x) <- names
colnames(x) <- names
x
```

# Factor

## Question 1
*For m = 2, 3, 4, and 5 construct a table showing $m$, $\hat{F}_{ML}$ , the
likelihood ratio test statistic ($\chi^2$, the degrees of freedom (*df*), the
effective number of free parameters in the model (*q*), the exceedance
probability (*p*-value) for the test of perfect fit, the exceedance probability
for the test of close fit, estimated RMSEA ($\hat\epsilon$) and the 90%
confidence interval for $\epsilon$.*

```{r, message=FALSE, warning=FALSE}
library(EFAutilities)
library(dplyr)

get_fa_stats <- function(m) {
  mod <- efa(
    covmat=x,
    rtype="orthogonal",
    factors=m,
    fm="ml",
    n.obs=746,
  )
  return(data.frame(
    factors=m,
    fit_ml=mod$fdiscrepancy[["Discrepancy"]],
    chi_2=mod$ModelF$f.stat[["Discrepancy"]],
    df=mod$ModelF$df,
    q=mod$nq,
    perfect_fit=mod$ModelF$p.perfect[["Discrepancy"]],
    close_fit=mod$ModelF$p.close[["Discrepancy"]],
    RMSEA=mod$ModelF$RMSEA[["Discrepancy"]],
    lower=mod$ModelF$RMSEA.l,
    upper=mod$ModelF$RMSEA.u
    ))
}

df <- vector("list", 4)

for(i in 2:5) {
 df[[i]] <- get_fa_stats(i)
}

# df <- do.call(rbind, df)
df <- df %>%
  do.call(rbind, .) %>% 
  mutate_if(is.numeric, round, digits=3)

df
```

## Question 2
*For the 4-factor solution, write a statement about the meaning of each of these pieces of information.*

  - The number of factors is a hyperparameter that determines how many latent variables the model assumes.
  - The $\hat{F}_{ML}$ statistic is the model loss, which we are attempting to minimize.
  - The $\chi^2$ statistic describes the likelihood ratio test statistic. It follows a $\chi^2$ distribution.
  - The degrees of freedom is the number of parameters that are estimated in the model.
  - The effective number of free parameters is the number of parameters that are estimated in the model, minus the number of parameters that are fixed to zero.
  - The exceedance p-value for the test of perfect fit indicates whether we can reject the null hypothesis that the model is a perfect fit to the data.
  - The exceedance  p-value for the test of close fit indicates whether we can reject the null hypothesis that the model is a close fit to the data.
  - The estimated RMSEA is the estimated root mean square error of approximation. It measures discrepancy per degree of freedom, with lower values indicating better fit.
  - The 90% confidence interval for $\epsilon$ (RMSEA) is the 90% confidence interval for the root mean square error of approximation. We would like to see some small numbers included in this interval.

## Question 3
*For the 4-factor solution, show the relationship between $\hat{F}_{ML}$ and the value of the $\chi^2$ test statistic.*

The $\chi^2$ test statistic is approximated by $(N - 1)\hat{F}_{ML}$.
```{r}
f_ml <- 1.379
num_obs <- 746
round((num_obs - 1) * f_ml)
```

## Question 4
*For the 4-factor solution, compute the unbiased estimate of the discrepancy function, $\hat{F}_{0}$, showing the relationship between $\hat{F}_{ML}$ and $\hat{F}_{0}$.*

The unbiased estimate of the discrepancy function is $\hat{F}_{0} = \max \left \{\hat{F}_{ML} - \frac{df}{N-1}, 0 \right\}$, where $df$ is the degrees of freedom and $N$ is the number of observations.

```{r}
df <- 24
max(f_ml - (df / (num_obs - 1)), 0)
```

## Question 5
*For the 4-factor solution, state how the confidence interval for RMSEA implies the result of the tests of exact fit and close fit.*

The test of exact fit is indicated by the lower bound of the confidence interval. Since the lower bound of this CI is not 0 for $m \in \{2,3,4,5\}$, we reject the null hypothesis that that any of these models are a perfect fit.

The test of close fit is also indicated by the lower bound of the confidence interval. Since the lower of this CI is < 0.05 for $m \in \{4,5\}$, we cannot reject the null hypothesis of close fit for these models.

## Question 6
*Based on the information in your table, how many factors should be retained? Justify your response.*

I would retain four factors because this is the smallest number of factors that passes the test of close fit. I also cheated by looking at the factor loadings, and the four factor model is the most interpetable because 4 sets of 3 MVs load neatly onto each factor. In the 5-factor model, loadings on the fifth factor are not as neat and tidy.

## Question 7
*For the 4-factor solution, compute the communality of the first variable from the factor loadings. Write one sentence interpreting this value. Show how this value is related to the corresponding unique variance in your output and write one sentence interpreting the meaning of that unique variance.*

```{r}
fa4 <- efa(
  covmat=x,
  rtype="orthogonal",
  factors=4,
  fm="ml",
  mnames=names,
  n.obs=746,
)
lambda <- fa4$unrotated
communalities <- rowSums(lambda^2)
cat("Communality:", communalities["LE"], "\n")
cat("Unique Variance:", fa4$compsi["LE", "UniV"])
```

The communality is the proportion of variance explained by the factors, so Law Enforcement (LE) has a very good proportion of its variance (almost .80!) explained by the factors. The communality is equal to $1 - \psi$, where $\psi$ is the unique variance. The unique variance indicates the proportion of variance that is not explained by the factors; it is the variance that is unique to a given manifest variable.

## Question 8
*For the 4-factor solution, compare the communalities to the SMCs and comment on their relationship.*

```{r}
fa4$compsi
```

The SMC is guaranteed to be a lower bound on the true communalities, so it is nice to see that the communalities are all larger than their respective SMC. In some cases, the communality is very close to the SMC, but in other cases, the communality is substantially larger than the SMC.

## Question 9
*For the 4-factor solution, compute the reconstructed correlation between the Law Enforcement (LE) and Acceptance of Social Order (AC) scales. Compare this value to the observed sample correlation and explain the meaning of the difference between these values.*

```{r}
vars_of_interest <- c("LE", "AC")
cat("Sample Correlation:", x["LE", "AC"], "\n")
cat("Reconstructed Correlation", fa4$Phat["LE", "AC"], "\n")
cat("Correlation Residual", fa4$Residual["LE", "AC"])
```

The reconstructed correlation between Law Enforcement (LE) and Acceptance of Social Order (AC) is almost identical to the correlation in the sample. The reconstructed correlation is slightly larger. The difference between these values is the correlation residual, which is the extent to which the model fails to recover the correlation

## Extra Credit

The rusty hull of a ship  
A welder's arc sends up  
bubbles of iron oxide fumes  


